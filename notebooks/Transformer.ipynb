{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUN3F-XE1dqr",
        "outputId": "38d5f67f-aa91-48bc-bbc6-a0b7e1cc0450"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentence-transformers in /home/whitewolf/DeepLearning/dlenv/lib/python3.11/site-packages (2.6.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /home/whitewolf/DeepLearning/dlenv/lib/python3.11/site-packages (from sentence-transformers) (4.39.2)\n",
            "Requirement already satisfied: tqdm in /home/whitewolf/DeepLearning/dlenv/lib/python3.11/site-packages (from sentence-transformers) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /home/whitewolf/DeepLearning/dlenv/lib/python3.11/site-packages (from sentence-transformers) (2.2.1)\n",
            "Requirement already satisfied: numpy in /home/whitewolf/DeepLearning/dlenv/lib/python3.11/site-packages (from sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /home/whitewolf/DeepLearning/dlenv/lib/python3.11/site-packages (from sentence-transformers) (1.4.0)\n",
            "Requirement already satisfied: scipy in /home/whitewolf/DeepLearning/dlenv/lib/python3.11/site-packages (from sentence-transformers) (1.12.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /home/whitewolf/DeepLearning/dlenv/lib/python3.11/site-packages (from sentence-transformers) (0.22.2)\n",
            "Requirement already satisfied: Pillow in /home/whitewolf/DeepLearning/dlenv/lib/python3.11/site-packages (from sentence-transformers) (10.2.0)\n",
            "Requirement already satisfied: filelock in /home/whitewolf/DeepLearning/dlenv/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /home/whitewolf/DeepLearning/dlenv/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.2.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /home/whitewolf/DeepLearning/dlenv/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/whitewolf/DeepLearning/dlenv/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: requests in /home/whitewolf/DeepLearning/dlenv/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/whitewolf/DeepLearning/dlenv/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.10.0)\n",
            "Requirement already satisfied: sympy in /home/whitewolf/DeepLearning/dlenv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /home/whitewolf/DeepLearning/dlenv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /home/whitewolf/DeepLearning/dlenv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/whitewolf/DeepLearning/dlenv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/whitewolf/DeepLearning/dlenv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/whitewolf/DeepLearning/dlenv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/whitewolf/DeepLearning/dlenv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/whitewolf/DeepLearning/dlenv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/whitewolf/DeepLearning/dlenv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/whitewolf/DeepLearning/dlenv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/whitewolf/DeepLearning/dlenv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/whitewolf/DeepLearning/dlenv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/whitewolf/DeepLearning/dlenv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/whitewolf/DeepLearning/dlenv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /home/whitewolf/DeepLearning/dlenv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/whitewolf/DeepLearning/dlenv/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.3.101)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/whitewolf/DeepLearning/dlenv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/whitewolf/DeepLearning/dlenv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /home/whitewolf/DeepLearning/dlenv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /home/whitewolf/DeepLearning/dlenv/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/whitewolf/DeepLearning/dlenv/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/whitewolf/DeepLearning/dlenv/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/whitewolf/DeepLearning/dlenv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/whitewolf/DeepLearning/dlenv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/whitewolf/DeepLearning/dlenv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/whitewolf/DeepLearning/dlenv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /home/whitewolf/DeepLearning/dlenv/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!python -m pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "aKCF9Q56ue-G"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "from typing import Dict\n",
        "from scipy.special import expit, softmax\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.functional import softmax\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoModel, AutoTokenizer, AutoModelForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "mmpWO07qaY1q"
      },
      "outputs": [],
      "source": [
        "class PreDUNES(nn.Module):\n",
        "    def __init__(self, twitter_embedding_model, twitter_sentiment_tokenizer, twitter_sentiment_model, reddit_sentiment_tokenizer, reddit_sentiment_model, twitter_sector_tokenizer, twitter_sector_model):\n",
        "        super(PreDUNES, self).__init__()\n",
        "        self.twitter_embedding_model = twitter_embedding_model\n",
        "        self.twitter_sentiment_tokenizer = twitter_sentiment_tokenizer\n",
        "        self.twitter_sentiment_model = twitter_sentiment_model\n",
        "        self.reddit_sentiment_tokenizer = reddit_sentiment_tokenizer\n",
        "        self.reddit_sentiment_model = reddit_sentiment_model\n",
        "        self.twitter_sector_tokenizer = twitter_sector_tokenizer\n",
        "        self.twitter_sector_model = twitter_sector_model\n",
        "\n",
        "    def forward(self, prev_tweet, prev_reddit):\n",
        "        prev_tweet_embedding = self.twitter_embedding_model.encode([prev_tweet], convert_to_tensor=True)\n",
        "        prev_tweet_tokens = self.twitter_sentiment_tokenizer(prev_tweet, return_tensors='pt')\n",
        "        prev_tweet_sentiment = self.twitter_sentiment_model(**prev_tweet_tokens).logits\n",
        "        \n",
        "        # Check if prev_reddit is None and handle accordingly\n",
        "        if prev_reddit is not None:\n",
        "            prev_reddit_tokens = self.reddit_sentiment_tokenizer(prev_reddit, return_tensors='pt')\n",
        "            prev_reddit_sentiment = self.reddit_sentiment_model(**prev_reddit_tokens).logits\n",
        "        else:\n",
        "            # Assuming the output size of your model to match when prev_reddit is not None\n",
        "            # Adjust the size to match your actual model output\n",
        "            prev_reddit_sentiment = torch.zeros_like(prev_tweet_sentiment) # Adjust this line as needed\n",
        "        \n",
        "        prev_sector_tokens = self.twitter_sector_tokenizer(prev_tweet, return_tensors='pt')\n",
        "        prev_tweet_sector = self.twitter_sector_model(**prev_sector_tokens).logits\n",
        "\n",
        "        return prev_tweet_embedding, prev_tweet_sentiment, prev_reddit_sentiment, prev_tweet_sector\n",
        "\n",
        "def create_preprocessing_model(twitter_embedding, twitter_sentiment, reddit_sentiment, twitter_sector):\n",
        "    twitter_embedding_model = SentenceTransformer(twitter_embedding)\n",
        "    twitter_sentiment_tokenizer = AutoTokenizer.from_pretrained(twitter_sentiment)\n",
        "    twitter_sentiment_model = AutoModelForSequenceClassification.from_pretrained(twitter_sentiment)\n",
        "    reddit_sentiment_tokenizer = AutoTokenizer.from_pretrained(reddit_sentiment)\n",
        "    reddit_sentiment_model = AutoModelForSequenceClassification.from_pretrained(reddit_sentiment)\n",
        "    twitter_sector_tokenizer = AutoTokenizer.from_pretrained(twitter_sector)\n",
        "    twitter_sector_model = AutoModelForSequenceClassification.from_pretrained(twitter_sector)\n",
        "\n",
        "    # Set models to evaluation mode\n",
        "    twitter_sentiment_model.eval()\n",
        "    reddit_sentiment_model.eval()\n",
        "    twitter_sector_model.eval()\n",
        "\n",
        "    # Disable gradients for models\n",
        "    for model in [twitter_sentiment_model, reddit_sentiment_model, twitter_sector_model]:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    model = PreDUNES(\n",
        "        twitter_embedding_model,\n",
        "        twitter_sentiment_tokenizer,\n",
        "        twitter_sentiment_model,\n",
        "        reddit_sentiment_tokenizer,\n",
        "        reddit_sentiment_model,\n",
        "        twitter_sector_tokenizer,\n",
        "        twitter_sector_model\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "preprocessing_model = create_preprocessing_model(\n",
        "    \"mixedbread-ai/mxbai-embed-large-v1\",\n",
        "    \"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
        "    \"bhadresh-savani/distilbert-base-uncased-emotion\",\n",
        "    \"cardiffnlp/tweet-topic-latest-multi\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DataLoaderDUNES(Dataset):\n",
        "    def __init__(self, data, preprocessing_model, seq_len=5, stride=1):\n",
        "        self.data = data\n",
        "        self.preprocessing_model = preprocessing_model\n",
        "        self.seq_len = seq_len\n",
        "        self.stride = stride\n",
        "        self.vector_size = 1024 + 3 + 6 + 19 + 5\n",
        "    \n",
        "    def calculate_vector_size(self):\n",
        "        sample = self.data[0]\n",
        "        outputs = self.preprocessing_model(sample['tweet_content'], sample['title_submission'])\n",
        "        total_size = sum(output.size(-1) for output in outputs)\n",
        "        return total_size\n",
        "    \n",
        "    def __len__(self):\n",
        "        return max(0, ((len(self.data) - self.seq_len) // self.stride) + 1)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        seq_features = torch.zeros((self.seq_len, self.vector_size))\n",
        "        start_idx = idx * self.stride\n",
        "\n",
        "        for i in range(self.seq_len):\n",
        "            data_idx = start_idx + i\n",
        "            if data_idx < len(self.data):\n",
        "                item = self.data[data_idx]\n",
        "\n",
        "                if i == self.seq_len - 1:  # Masking for nth tweet\n",
        "                    prev_tweet_embedding, prev_tweet_sentiment, _, _ = self.preprocessing_model(item['tweet_content'], None)\n",
        "                    # Ensure prev_tweet_embedding is flattened to match dimensions\n",
        "                    prev_tweet_embedding = prev_tweet_embedding.view(-1)  \n",
        "                    prev_tweet_sentiment = prev_tweet_sentiment.view(-1)  \n",
        "                    # Create a mask tensor with the appropriate length\n",
        "                    mask_tensor = torch.zeros(self.vector_size - prev_tweet_embedding.size(0) - prev_tweet_sentiment.size(0))\n",
        "                    all_features = torch.cat([prev_tweet_embedding, prev_tweet_sentiment, mask_tensor])\n",
        "                else:\n",
        "                    prev_tweet_embedding, prev_tweet_sentiment, prev_reddit_sentiment, prev_tweet_sector = self.preprocessing_model(item['tweet_content'], item['title_submission'])\n",
        "                    # Flatten and concatenate all features\n",
        "                    prev_tweet_embedding = prev_tweet_embedding.view(-1)\n",
        "                    prev_tweet_sentiment = prev_tweet_sentiment.view(-1)\n",
        "                    prev_reddit_sentiment = prev_reddit_sentiment.view(-1)\n",
        "                    prev_tweet_sector = prev_tweet_sector.view(-1)\n",
        "                    additional_data = torch.tensor([item['num_likes'], item['num_retweets'], item['num_replies'], item['score_submission'], item['positive_comments'],item['positive_scores'],item['negative_comments'],item['negative_score']], dtype=torch.float).view(-1)\n",
        "                    all_features = torch.cat([prev_tweet_embedding, prev_tweet_sentiment, prev_reddit_sentiment, prev_tweet_sector, additional_data])\n",
        "\n",
        "                seq_features[i, :all_features.size(0)] = all_features\n",
        "\n",
        "        return seq_features.unsqueeze(0) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "csv_file_path = 'Dataset/COMBINED_FINAL.csv'\n",
        "\n",
        "df = pd.read_csv(csv_file_path)\n",
        "data = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "\n",
        "    row_dict = {\n",
        "        'tweet_url': row['tweet_url'],\n",
        "        'created_at': row['created_at'],\n",
        "        'tweet_content': row['tweet_content'],\n",
        "        'num_likes': row['num_likes'],\n",
        "        'num_retweets': row['num_retweets'],\n",
        "        'num_replies': row['num_replies'],\n",
        "        'title_submission': row['title_submission'],\n",
        "        'num_comments': row['num_comments'],\n",
        "        'score_submission': row['score_submission'],\n",
        "        'positive_comments': row['positive_comments'],\n",
        "        'positive_scores': row['positive_scores'],\n",
        "        'negative_comments': row['negative_comments'],\n",
        "        'negative_scores': row['negative_scores']\n",
        "    }\n",
        "\n",
        "    data.append(row_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "# data = [\n",
        "#     {\n",
        "#         'prev_tweet': \"@WholeMarsBlog Headline is misleading. Starlink can obviously offer far more robust positioning than GPS, as it will have ~1000X more satellites over time. Not all will have line of sight to users, but still >10X GPS & far stronger signal. Just not today’s problem.\",\n",
        "#         'curr_tweet': \"@spideycyp_155 @BillyM2k If Russia faced calamitous defeat in conventional warfare for something as strategically critical as Crimea, the probability of using nuclear weapons is high\",\n",
        "#         'prev_reddit': \"We know who controls the media. The same corporations who have wreaked havoc on the globe for decades, if not centuries, the big banks who financed them, and the governments who turned a blind eye to the destruction. The same entities who have brought us to the precipice of destruction - quite possibly condemning us, and our progeny to an unlivable climate They have tried to stop you at every turn, and yet you persist for the good of humanity. We love you, Elon! Keep up the good work! As you have said, we must never let the light of human consciousness fade - never!\",\n",
        "#         'likes': 100,  \n",
        "#         'retweets': 50, \n",
        "#         'comments': 25,\n",
        "#         'reddit_score': 0.8,\n",
        "#         'rcomments': 45          \n",
        "#     }\n",
        "# ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset length: 4034\n"
          ]
        }
      ],
      "source": [
        "dataset = DataLoaderDUNES(data, preprocessing_model, seq_len=1, stride=1)  #for immediate testing of first data point\n",
        "print(\"Dataset length:\", len(dataset))\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, 1, d_model)\n",
        "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0)]\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, input_vector_size, d_model, nhead, num_encoder_layers, dim_feedforward, num_outputs):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.positional_encoder = PositionalEncoding(d_model)\n",
        "        self.input_projection = nn.Linear(input_vector_size, d_model)  \n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
        "        self.output_linear = nn.Linear(d_model, num_outputs)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len, vector_size = x.size()\n",
        "        x = x.view(batch_size * seq_len, vector_size) \n",
        "        x = self.input_projection(x)  \n",
        "        x = x.view(batch_size, seq_len, -1)  \n",
        "        x = self.positional_encoder(x)\n",
        "        x = torch.mean(self.transformer_encoder(x), dim=1)  \n",
        "        return self.output_linear(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/whitewolf/DeepLearning/dlenv/lib/python3.11/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        }
      ],
      "source": [
        "input_vector_size = 1024 + 3 + 6 + 19 + 5\n",
        "model = TransformerModel(\n",
        "    input_vector_size= input_vector_size,  \n",
        "    d_model=512,\n",
        "    nhead=8,\n",
        "    num_encoder_layers=3,\n",
        "    dim_feedforward=2048,\n",
        "    num_outputs=3\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_projection.weight: torch.Size([512, 1057])\n",
            "input_projection.bias: torch.Size([512])\n",
            "transformer_encoder.layers.0.self_attn.in_proj_weight: torch.Size([1536, 512])\n",
            "transformer_encoder.layers.0.self_attn.in_proj_bias: torch.Size([1536])\n",
            "transformer_encoder.layers.0.self_attn.out_proj.weight: torch.Size([512, 512])\n",
            "transformer_encoder.layers.0.self_attn.out_proj.bias: torch.Size([512])\n",
            "transformer_encoder.layers.0.linear1.weight: torch.Size([2048, 512])\n",
            "transformer_encoder.layers.0.linear1.bias: torch.Size([2048])\n",
            "transformer_encoder.layers.0.linear2.weight: torch.Size([512, 2048])\n",
            "transformer_encoder.layers.0.linear2.bias: torch.Size([512])\n",
            "transformer_encoder.layers.0.norm1.weight: torch.Size([512])\n",
            "transformer_encoder.layers.0.norm1.bias: torch.Size([512])\n",
            "transformer_encoder.layers.0.norm2.weight: torch.Size([512])\n",
            "transformer_encoder.layers.0.norm2.bias: torch.Size([512])\n",
            "transformer_encoder.layers.1.self_attn.in_proj_weight: torch.Size([1536, 512])\n",
            "transformer_encoder.layers.1.self_attn.in_proj_bias: torch.Size([1536])\n",
            "transformer_encoder.layers.1.self_attn.out_proj.weight: torch.Size([512, 512])\n",
            "transformer_encoder.layers.1.self_attn.out_proj.bias: torch.Size([512])\n",
            "transformer_encoder.layers.1.linear1.weight: torch.Size([2048, 512])\n",
            "transformer_encoder.layers.1.linear1.bias: torch.Size([2048])\n",
            "transformer_encoder.layers.1.linear2.weight: torch.Size([512, 2048])\n",
            "transformer_encoder.layers.1.linear2.bias: torch.Size([512])\n",
            "transformer_encoder.layers.1.norm1.weight: torch.Size([512])\n",
            "transformer_encoder.layers.1.norm1.bias: torch.Size([512])\n",
            "transformer_encoder.layers.1.norm2.weight: torch.Size([512])\n",
            "transformer_encoder.layers.1.norm2.bias: torch.Size([512])\n",
            "transformer_encoder.layers.2.self_attn.in_proj_weight: torch.Size([1536, 512])\n",
            "transformer_encoder.layers.2.self_attn.in_proj_bias: torch.Size([1536])\n",
            "transformer_encoder.layers.2.self_attn.out_proj.weight: torch.Size([512, 512])\n",
            "transformer_encoder.layers.2.self_attn.out_proj.bias: torch.Size([512])\n",
            "transformer_encoder.layers.2.linear1.weight: torch.Size([2048, 512])\n",
            "transformer_encoder.layers.2.linear1.bias: torch.Size([2048])\n",
            "transformer_encoder.layers.2.linear2.weight: torch.Size([512, 2048])\n",
            "transformer_encoder.layers.2.linear2.bias: torch.Size([512])\n",
            "transformer_encoder.layers.2.norm1.weight: torch.Size([512])\n",
            "transformer_encoder.layers.2.norm1.bias: torch.Size([512])\n",
            "transformer_encoder.layers.2.norm2.weight: torch.Size([512])\n",
            "transformer_encoder.layers.2.norm2.bias: torch.Size([512])\n",
            "output_linear.weight: torch.Size([3, 512])\n",
            "output_linear.bias: torch.Size([3])\n"
          ]
        }
      ],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(f\"{name}: {param.size()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=0.001)\n",
        "num_epochs = 25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/home/whitewolf/csci566s-24/notebooks/Transformer.ipynb Cell 14\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/whitewolf/csci566s-24/notebooks/Transformer.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39mtrain()  \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/whitewolf/csci566s-24/notebooks/Transformer.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m train_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/whitewolf/csci566s-24/notebooks/Transformer.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;49;00m batch \u001b[39min\u001b[39;49;00m dataloader:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/whitewolf/csci566s-24/notebooks/Transformer.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m# print(batch)\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/whitewolf/csci566s-24/notebooks/Transformer.ipynb#X15sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     optimizer\u001b[39m.\u001b[39;49mzero_grad()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/whitewolf/csci566s-24/notebooks/Transformer.ipynb#X15sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     batch \u001b[39m=\u001b[39;49m batch\u001b[39m.\u001b[39;49msqueeze(\u001b[39m0\u001b[39;49m)\n",
            "File \u001b[0;32m~/DeepLearning/dlenv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    632\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m~/DeepLearning/dlenv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[0;32m~/DeepLearning/dlenv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[0;32m~/DeepLearning/dlenv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
            "\u001b[1;32m/home/whitewolf/csci566s-24/notebooks/Transformer.ipynb Cell 14\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/whitewolf/csci566s-24/notebooks/Transformer.ipynb#X15sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[data_idx]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/whitewolf/csci566s-24/notebooks/Transformer.ipynb#X15sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseq_len \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m:  \u001b[39m# Masking for nth tweet\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/whitewolf/csci566s-24/notebooks/Transformer.ipynb#X15sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     prev_tweet_embedding, prev_tweet_sentiment, _, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpreprocessing_model(item[\u001b[39m'\u001b[39;49m\u001b[39mtweet_content\u001b[39;49m\u001b[39m'\u001b[39;49m], \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/whitewolf/csci566s-24/notebooks/Transformer.ipynb#X15sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39m# Ensure prev_tweet_embedding is flattened to match dimensions\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/whitewolf/csci566s-24/notebooks/Transformer.ipynb#X15sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     prev_tweet_embedding \u001b[39m=\u001b[39m prev_tweet_embedding\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)  \n",
            "File \u001b[0;32m~/DeepLearning/dlenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/DeepLearning/dlenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "\u001b[1;32m/home/whitewolf/csci566s-24/notebooks/Transformer.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/whitewolf/csci566s-24/notebooks/Transformer.ipynb#X15sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, prev_tweet, prev_reddit):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/whitewolf/csci566s-24/notebooks/Transformer.ipynb#X15sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     prev_tweet_embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtwitter_embedding_model\u001b[39m.\u001b[39;49mencode([prev_tweet], convert_to_tensor\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/whitewolf/csci566s-24/notebooks/Transformer.ipynb#X15sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     prev_tweet_tokens \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtwitter_sentiment_tokenizer(prev_tweet, return_tensors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/whitewolf/csci566s-24/notebooks/Transformer.ipynb#X15sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     prev_tweet_sentiment \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtwitter_sentiment_model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mprev_tweet_tokens)\u001b[39m.\u001b[39mlogits\n",
            "File \u001b[0;32m~/DeepLearning/dlenv/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:357\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    354\u001b[0m features\u001b[39m.\u001b[39mupdate(extra_features)\n\u001b[1;32m    356\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 357\u001b[0m     out_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(features)\n\u001b[1;32m    359\u001b[0m     \u001b[39mif\u001b[39;00m output_value \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtoken_embeddings\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    360\u001b[0m         embeddings \u001b[39m=\u001b[39m []\n",
            "File \u001b[0;32m~/DeepLearning/dlenv/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
            "File \u001b[0;32m~/DeepLearning/dlenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/DeepLearning/dlenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/DeepLearning/dlenv/lib/python3.11/site-packages/sentence_transformers/models/Transformer.py:98\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m features:\n\u001b[1;32m     96\u001b[0m     trans_features[\u001b[39m\"\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m features[\u001b[39m\"\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m---> 98\u001b[0m output_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mauto_model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtrans_features, return_dict\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     99\u001b[0m output_tokens \u001b[39m=\u001b[39m output_states[\u001b[39m0\u001b[39m]\n\u001b[1;32m    101\u001b[0m features\u001b[39m.\u001b[39mupdate({\u001b[39m\"\u001b[39m\u001b[39mtoken_embeddings\u001b[39m\u001b[39m\"\u001b[39m: output_tokens, \u001b[39m\"\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m\"\u001b[39m: features[\u001b[39m\"\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m\"\u001b[39m]})\n",
            "File \u001b[0;32m~/DeepLearning/dlenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/DeepLearning/dlenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/DeepLearning/dlenv/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:1013\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1004\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m   1006\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m   1007\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m   1008\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1011\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[1;32m   1012\u001b[0m )\n\u001b[0;32m-> 1013\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m   1014\u001b[0m     embedding_output,\n\u001b[1;32m   1015\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m   1016\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1017\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1018\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m   1019\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1020\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1021\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1022\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1023\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1024\u001b[0m )\n\u001b[1;32m   1025\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1026\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/DeepLearning/dlenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/DeepLearning/dlenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/DeepLearning/dlenv/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:607\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    596\u001b[0m     layer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    597\u001b[0m         layer_module\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m,\n\u001b[1;32m    598\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    604\u001b[0m         output_attentions,\n\u001b[1;32m    605\u001b[0m     )\n\u001b[1;32m    606\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 607\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    608\u001b[0m         hidden_states,\n\u001b[1;32m    609\u001b[0m         attention_mask,\n\u001b[1;32m    610\u001b[0m         layer_head_mask,\n\u001b[1;32m    611\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    612\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    613\u001b[0m         past_key_value,\n\u001b[1;32m    614\u001b[0m         output_attentions,\n\u001b[1;32m    615\u001b[0m     )\n\u001b[1;32m    617\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    618\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
            "File \u001b[0;32m~/DeepLearning/dlenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/DeepLearning/dlenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/DeepLearning/dlenv/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:497\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    486\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    487\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    494\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m    495\u001b[0m     \u001b[39m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    496\u001b[0m     self_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[:\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 497\u001b[0m     self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[1;32m    498\u001b[0m         hidden_states,\n\u001b[1;32m    499\u001b[0m         attention_mask,\n\u001b[1;32m    500\u001b[0m         head_mask,\n\u001b[1;32m    501\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    502\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[1;32m    503\u001b[0m     )\n\u001b[1;32m    504\u001b[0m     attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    506\u001b[0m     \u001b[39m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
            "File \u001b[0;32m~/DeepLearning/dlenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/DeepLearning/dlenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/DeepLearning/dlenv/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:427\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    418\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    419\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    425\u001b[0m     output_attentions: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    426\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[0;32m--> 427\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself(\n\u001b[1;32m    428\u001b[0m         hidden_states,\n\u001b[1;32m    429\u001b[0m         attention_mask,\n\u001b[1;32m    430\u001b[0m         head_mask,\n\u001b[1;32m    431\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    432\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    433\u001b[0m         past_key_value,\n\u001b[1;32m    434\u001b[0m         output_attentions,\n\u001b[1;32m    435\u001b[0m     )\n\u001b[1;32m    436\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(self_outputs[\u001b[39m0\u001b[39m], hidden_states)\n\u001b[1;32m    437\u001b[0m     outputs \u001b[39m=\u001b[39m (attention_output,) \u001b[39m+\u001b[39m self_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
            "File \u001b[0;32m~/DeepLearning/dlenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/DeepLearning/dlenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/DeepLearning/dlenv/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:359\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    355\u001b[0m attention_probs \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39msoftmax(attention_scores, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    357\u001b[0m \u001b[39m# This is actually dropping out entire tokens to attend to, which might\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[39m# seem a bit unusual, but is taken from the original Transformer paper.\u001b[39;00m\n\u001b[0;32m--> 359\u001b[0m attention_probs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout(attention_probs)\n\u001b[1;32m    361\u001b[0m \u001b[39m# Mask heads if we want to\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[39mif\u001b[39;00m head_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "File \u001b[0;32m~/DeepLearning/dlenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/DeepLearning/dlenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/DeepLearning/dlenv/lib/python3.11/site-packages/torch/nn/modules/dropout.py:58\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mDropout\u001b[39;00m(_DropoutNd):\n\u001b[1;32m     25\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"During training, randomly zeroes some of the elements of the input tensor with probability :attr:`p`.\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \n\u001b[1;32m     27\u001b[0m \u001b[39m    The zeroed elements are chosen independently for each forward call and are sampled from a Bernoulli distribution.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m        detectors: https://arxiv.org/abs/1207.0580\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m     59\u001b[0m         \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mdropout(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mp, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minplace)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    model.train()  \n",
        "    train_loss = 0.0\n",
        "\n",
        "    for batch in dataloader:\n",
        "        # print(batch)\n",
        "        optimizer.zero_grad()\n",
        "        batch = batch.squeeze(0)\n",
        "        inputs = batch[:, :, :]  \n",
        "        targets = batch[:, -1, -5:-2]  # Assuming these are structured at the end of each sequence\n",
        "\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Calculate loss between the model's predictions and the actual engagement metrics\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "\n",
        "    avg_train_loss = train_loss / len(dataloader)\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'validation_dataloader' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/home/whitewolf/csci566s-24/notebooks/Transformer.ipynb Cell 14\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/whitewolf/csci566s-24/notebooks/Transformer.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m total_predictions \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/whitewolf/csci566s-24/notebooks/Transformer.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m total_targets \u001b[39m=\u001b[39m []\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/whitewolf/csci566s-24/notebooks/Transformer.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m validation_dataloader:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/whitewolf/csci566s-24/notebooks/Transformer.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     features \u001b[39m=\u001b[39m {\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/whitewolf/csci566s-24/notebooks/Transformer.ipynb#X16sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mprev_tweet_embedding\u001b[39m\u001b[39m'\u001b[39m: batch[\u001b[39m'\u001b[39m\u001b[39mprev_tweet_embedding\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/whitewolf/csci566s-24/notebooks/Transformer.ipynb#X16sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mprev_tweet_sentiment\u001b[39m\u001b[39m'\u001b[39m: batch[\u001b[39m'\u001b[39m\u001b[39mprev_tweet_sentiment\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/whitewolf/csci566s-24/notebooks/Transformer.ipynb#X16sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mprev_reddit_sentiment\u001b[39m\u001b[39m'\u001b[39m: batch[\u001b[39m'\u001b[39m\u001b[39mprev_reddit_sentiment\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/whitewolf/csci566s-24/notebooks/Transformer.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mprev_tweet_sector\u001b[39m\u001b[39m'\u001b[39m: batch[\u001b[39m'\u001b[39m\u001b[39mprev_tweet_sector\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/whitewolf/csci566s-24/notebooks/Transformer.ipynb#X16sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     }\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/whitewolf/csci566s-24/notebooks/Transformer.ipynb#X16sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     targets \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack((batch[\u001b[39m'\u001b[39m\u001b[39mlikes\u001b[39m\u001b[39m'\u001b[39m], batch[\u001b[39m'\u001b[39m\u001b[39mretweets\u001b[39m\u001b[39m'\u001b[39m], batch[\u001b[39m'\u001b[39m\u001b[39mcomments\u001b[39m\u001b[39m'\u001b[39m]), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'validation_dataloader' is not defined"
          ]
        }
      ],
      "source": [
        "# Prediction phase\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "with torch.no_grad():  # Disable gradient calculation\n",
        "    total_predictions = []\n",
        "    total_targets = []\n",
        "    for batch in validation_dataloader:\n",
        "        features = {\n",
        "            'prev_tweet_embedding': batch['prev_tweet_embedding'],\n",
        "            'prev_tweet_sentiment': batch['prev_tweet_sentiment'],\n",
        "            'prev_reddit_sentiment': batch['prev_reddit_sentiment'],\n",
        "            'prev_tweet_sector': batch['prev_tweet_sector'],\n",
        "        }\n",
        "        targets = torch.stack((batch['likes'], batch['retweets'], batch['comments']), dim=1)\n",
        "        predictions = model(features)\n",
        "        total_predictions.append(predictions)\n",
        "        total_targets.append(targets)\n",
        "    \n",
        "    # Conversion to numpy for analysis (optional)\n",
        "    predictions_np = torch.cat(total_predictions, dim=0).cpu().numpy()\n",
        "    targets_np = torch.cat(total_targets, dim=0).cpu().numpy()\n",
        "    # Use predictions_np and targets_np for further analysis\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
